{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## loading required data and libs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "! pip install kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp \"env/kaggle.json\" ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle competitions download -c AI4Code\n",
    "! mkdir data\n",
    "! unzip -n AI4Code.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (3.3.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.1.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.7.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (59.8.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (4.11.4)\n",
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'environment/requirenments.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
      "  Using cached transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.12.0+cu113)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Using cached huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.7.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.11.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.7.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=33a0a0373ebf13054ea157c42d1515bd0a51fa76af7c4f1016e38081b1081abd\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, regex, filelock, huggingface-hub, transformers, nltk, sentence-transformers\n",
      "Successfully installed filelock-3.7.1 huggingface-hub-0.8.1 nltk-3.7 regex-2022.7.9 sentence-transformers-2.2.2 sentencepiece-0.1.96 tokenizers-0.12.1 transformers-4.20.1\n",
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.12.0+cu113)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torchaudio-0.12.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.1.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.1)\n",
      "  Downloading torchaudio-0.12.0-cp37-cp37m-manylinux1_x86_64.whl (3.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Downloading https://download.pytorch.org/whl/cpu/torchaudio-0.11.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-0.11.0+cpu\n",
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.19.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (59.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.11.4)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting contextualSpellCheck\n",
      "  Using cached contextualSpellCheck-0.4.1-py3-none-any.whl (132 kB)\n",
      "Collecting editdistance==0.5.3\n",
      "  Using cached editdistance-0.5.3-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
      "Requirement already satisfied: spacy>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck) (3.3.1)\n",
      "Requirement already satisfied: transformers>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck) (4.20.1)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck) (1.11.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (2.28.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (0.4.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (2.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (3.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (1.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (1.19.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (0.9.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (3.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (59.8.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (4.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (21.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (3.1.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (4.64.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (1.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (2.4.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (8.0.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (0.7.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (2022.7.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (0.8.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (4.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (3.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->contextualSpellCheck) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy>=3.0.0->contextualSpellCheck) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy>=3.0.0->contextualSpellCheck) (5.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (2.1.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->contextualSpellCheck) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy>=3.0.0->contextualSpellCheck) (2.1.1)\n",
      "Installing collected packages: editdistance, contextualSpellCheck\n",
      "Successfully installed contextualSpellCheck-0.4.1 editdistance-0.5.3\n",
      "Collecting autocorrect\n",
      "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m622.8/622.8 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=9a27b33fbb5bc62a2ccd33d51bb4f55cc9021cc539dc153092672cdd35927d61\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.6.1\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.7/site-packages (1.7.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U spacy\n",
    "! pip install -U -r environment/requirenments.txt\n",
    "! pip install -U sentence-transformers\n",
    "! pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "# ! python -m spacy download en_core_web_lg\n",
    "! python -m spacy download en_core_web_sm\n",
    "!pip install contextualSpellCheck\n",
    "!pip install autocorrect\n",
    "!pip install emoji\n",
    "! pip install ipywidgets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import gc\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "from autocorrect import Speller\n",
    "import json\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import tokenize\n",
    "from tokenize import TokenError\n",
    "import io\n",
    "tqdm.pandas()\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import torch\n",
    "from sentence_transformers import util\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import emoji\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "import scipy\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sys\n",
    "import textwrap\n",
    "import wandb\n",
    "import spacy\n",
    "import contextualSpellCheck\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bisect import bisect\n",
    "from time import time\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "data_dir = Path('data/')\n",
    "sys.path.append(str('AI4Code'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "def read_train_data(data_dir, NUM_TRAIN = 10000, OFFSET=0):\n",
    "    def read_notebook(path):\n",
    "        return (\n",
    "            pd.read_json(\n",
    "                path,\n",
    "                dtype={'cell_type': 'category', 'source': 'str'})\n",
    "            .assign(id=path.stem)  # final path component\n",
    "            .rename_axis('cell_id')\n",
    "        )\n",
    "\n",
    "    paths_train = list((data_dir / 'train').glob('*.json'))[OFFSET:NUM_TRAIN]\n",
    "    notebooks_train = [\n",
    "      read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n",
    "    ]\n",
    "    df = (\n",
    "      pd.concat(notebooks_train)\n",
    "      .set_index('id', append=True)\n",
    "      .swaplevel()\n",
    "      .sort_index(level='id', sort_remaining=False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def get_df_orders_and_ranks(df, data_dir):\n",
    "    # train orders\n",
    "    df_orders = pd.read_csv(\n",
    "      data_dir / 'train_orders.csv',\n",
    "      index_col='id',\n",
    "      squeeze=True,\n",
    "    ).str.split()  # cell_ids str -> list\n",
    "\n",
    "\n",
    "    df_orders_ = df_orders.to_frame().join(\n",
    "      # reset only one index out of many -> \"cell_id\"; make a list out of cells in train data\n",
    "      df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "      how='right',\n",
    "    )\n",
    "\n",
    "    ranks = {}\n",
    "    for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "        ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "    df_ranks = (\n",
    "      pd.DataFrame\n",
    "      .from_dict(ranks, orient='index')\n",
    "      .rename_axis('id')\n",
    "      .apply(pd.Series.explode)\n",
    "      .set_index('cell_id', append=True)\n",
    "    )\n",
    "    # now we have\n",
    "    # id cell_id rank\n",
    "    return df_orders, df_ranks\n",
    "\n",
    "\n",
    "def get_ancestors(data_dir, ids):\n",
    "    # Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "    df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n",
    "    return df_ancestors.loc[ids, 'ancestor_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## text utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spell = Speller(fast=True)\n",
    "def correct_spelling(text):\n",
    "    if text:\n",
    "        return spell(text)\n",
    "    else:\n",
    "        return text\n",
    "        \n",
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove square brackets, replace links with \"link\" ,\n",
    "    and remove words containing numbers with \"number\".'''\n",
    "    if not text:\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    text = re.sub('<.*?>+', ' ', text)\n",
    "    text = text.replace('[' , ' ')\n",
    "    text = text.replace(']' , ' ')\n",
    "    text = re.sub('http.?://\\S+|www\\.\\S+', 'link', text)\n",
    "    # text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = re.sub('\\n', '. ', text)\n",
    "    text = re.sub('\\w*\\d\\w*', 'number', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    Cleaning and parsing the text.\n",
    "\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    nopunc = clean_text(text)\n",
    "    tokenized_text = tokenizer.tokenize(nopunc)\n",
    "    combined_text = ' '.join(tokenized_text)\n",
    "    return combined_text\n",
    "\n",
    "\n",
    "image_pattern = r'(!\\[([^\\]]*)\\]\\((.*?)\\s*(\"(?:.*[^\"])\")?\\s*\\))'\n",
    "def replace_image_with_label(text):\n",
    "    matches = re.findall(image_pattern, text)\n",
    "    for match in matches:\n",
    "        if match[1]:\n",
    "            result = text_preprocessing(' '.join(match[1].split('.')[:-1]))\n",
    "            result = \"image link \" + ' '.join(result.split(\"_\"))\n",
    "        else:\n",
    "            result = \"image link \"\n",
    "        text = text.replace(match[0], result)\n",
    "    return text_preprocessing(text)\n",
    "\n",
    "\n",
    "def clean_code(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.replace('[', ' ').replace(']', ' ').replace('(', ' ')\\\n",
    "    .replace(')', ' ').replace('{', ' ').replace('}', ' ').replace('=', ' ').replace(',', ' ')\n",
    "    text = text.lower()\n",
    "    text = text.replace('_', ' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('.', ' ')\n",
    "    text = re.sub(r'\".*\"', ' ', text)\n",
    "    text = re.sub(r\"'.*'\", ' ', text)\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def code_preprocessing(text):\n",
    "    \"\"\"\n",
    "    Cleaning and parsing the text.\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    nopunc = clean_code(text)\n",
    "    tokenized_text = tokenizer.tokenize(nopunc)\n",
    "    combined_text = ' '.join(tokenized_text)\n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14c8cc65e984e0f9f24a715bb50141d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train NBs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape is (44337, 2)\n"
     ]
    }
   ],
   "source": [
    "# example pipeline work\n",
    "df = read_train_data(data_dir, NUM_TRAIN=1000)\n",
    "df_orders, df_ranks = get_df_orders_and_ranks(df, data_dir)\n",
    "\n",
    "print(f\"Df shape is {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Small features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### additional load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_entities(unload=False):\n",
    "    global ner\n",
    "    if not unload:\n",
    "        ner = spacy.load(\"en_core_web_sm\")\n",
    "    else:\n",
    "        del ner\n",
    "\n",
    "def load_ml_glossary(unload=False):\n",
    "    global embedder, terms, corpus_embeddings\n",
    "    if not unload:\n",
    "        embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        ml_glossary = pd.read_csv(\"machine_learning_glossary_terms.csv\")\n",
    "        # sentences we will be searching through\n",
    "        corpus = np.array(ml_glossary['definition'])\n",
    "        terms = np.array(ml_glossary['term'])\n",
    "        corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "    else:\n",
    "        del embedder, corpus_embeddings\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### general implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "additional_load = {\n",
    "    \"collect_entities\": load_entities,\n",
    "    \"get_top_glossary_terms\": load_ml_glossary\n",
    "}\n",
    "\n",
    "def prepare_data(df, func, new_column, on_column='source'):\n",
    "    tic = time()\n",
    "    func_name = func.__name__\n",
    "    print(f\"{func_name} on {on_column} -> {new_column} column\")\n",
    "    if func_name in additional_load:\n",
    "        additional_load[func_name]()\n",
    "    df[new_column] = df.progress_apply(lambda x: func(x[on_column]), axis=1)\n",
    "    if func_name in additional_load:\n",
    "        additional_load[func_name](unload=True)\n",
    "    toc = time()\n",
    "    print(f\"COMPLETION TIME = {toc-tic:.1f} s\")\n",
    "    print(\"-\"*25+\">\")\n",
    "    print(\"\\n\")\n",
    "    return df\n",
    "\n",
    "def prepare_data_with_vector(df, func, new_column, on_column='source'):\n",
    "    tic = time()\n",
    "    func_name = func.__name__\n",
    "    if func_name in additional_load:\n",
    "        additional_load[func_name]()\n",
    "    print(f\"{func.__name__} on {on_column} -> {new_column} column ...\")\n",
    "    vector = df.progress_apply(lambda x: func(x[on_column]), axis=1).values\n",
    "    if func_name in additional_load:\n",
    "        additional_load[func_name](unload=True)\n",
    "    new_columns = [f\"{new_column}_{x}\" for x in range(len(vector[0]))]\n",
    "    vector_df = pd.DataFrame(np.row_stack(vector), columns=new_columns)  \n",
    "    # todo return vector and the stack them\n",
    "    df = pd.concat([df, vector_df], ignore_index=False, axis=1)\n",
    "    \n",
    "    toc = time()\n",
    "    print(f\"COMPLETION TIME = {toc-tic:.1f} s\")\n",
    "    print(\"-\"*25+\">\")\n",
    "    print(\"\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### tokenizing python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_python_code_names(text):\n",
    "    try:\n",
    "        code_text = tokenize.generate_tokens(io.StringIO(text).readline)\n",
    "        strings = [tok.string for tok in code_text if tok.type==1]\n",
    "    except Exception:\n",
    "        return None # Error happened\n",
    "    return ' '.join(strings)\n",
    "\n",
    "def tokenize_python_code_comments(text):\n",
    "    try:\n",
    "        code_text = tokenize.generate_tokens(io.StringIO(text).readline)\n",
    "        strings = [tok.string for tok in code_text if tok.type==55]\n",
    "    except Exception:\n",
    "        return None # Error happened\n",
    "    return ' '.join(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### lemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lem = nltk.stem.wordnet.WordNetLemmatizer()  # lemmatizer  \n",
    "def lemm_sentence(text):\n",
    "    lst_txt = [lem.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(lst_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_entities(text):\n",
    "    \"Named Entity Recognition\"\n",
    "    rs = ner(text)\n",
    "    labels = []\n",
    "    for r in rs.ents:\n",
    "        labels.append(r.label_)\n",
    "    return ' '.join(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### heading order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hedding_order(text) -> int:\n",
    "    \"\"\" Get heading order \"\"\"\n",
    "    text = text.strip()\n",
    "    heading_number = text.split(\" \")[0].count(\"#\")\n",
    "    if len(text.split(\" \")[0]) != heading_number or not heading_number:\n",
    "        return None\n",
    "    return heading_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TFID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_TfidfVector(df, max_features=100):\n",
    "    tfidf = TfidfVectorizer(min_df=0.01, max_features=max_features)\n",
    "    return tfidf, tfidf.fit_transform(df.astype(str))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ALPHA 1 todo list\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# todo collect the list of tags in machine learning and find it among the most popular words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Machine Learning glossary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# better do not vector but words and the put them to TFID\n",
    "top_k=5\n",
    "def get_top_glossary_terms(query):\n",
    "    output_vector = np.zeros((len(terms)))\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k, query_chunk_size=500)\n",
    "    # todo add threshold 0.5? mb\n",
    "    output_vector[[hit['corpus_id'] for hit in hits[0]]] = [hit['score'] for hit in hits[0]]\n",
    "    return output_vector\n",
    "# Adds len(terms) = 249 columns to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, func, new_column='source', on_column='source'):\n",
    "    tic = time()\n",
    "    func_name = func.__name__\n",
    "    print(f\"{func_name} on {on_column} -> {new_column} column\")\n",
    "    if func_name in additional_load:\n",
    "        additional_load[func_name]()\n",
    "    df[new_column] = df.progress_apply(lambda x: func(x[on_column]), axis=1)\n",
    "    if func_name in additional_load:\n",
    "        additional_load[func_name](unload=True)\n",
    "    toc = time()\n",
    "    print(f\"COMPLETION TIME = {toc-tic:.1f} s\")\n",
    "    print(\"-\"*25+\">\")\n",
    "    print(\"\\n\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_markdown_source_clean(df):\n",
    "    # better run them firstly\n",
    "    df = prepare_data(df, get_hedding_order, \"heading_order\")\n",
    "    df = prepare_data(df, collect_entities, \"entities\")\n",
    "    \n",
    "    # cleaning\n",
    "    df = prepare_data(df, replace_image_with_label)\n",
    "    df = prepare_data(df, text_preprocessing)\n",
    "    df = prepare_data(df, correct_spelling)\n",
    "    \n",
    "    # feature extraction on clean text\n",
    "    df = prepare_data_with_vector(df, get_top_glossary_terms, \"glossary_ml_terms\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## markdown pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "markdowns_pipeline = Pipeline([    \n",
    "    ('Heading order', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': get_hedding_order,\n",
    "             'new_column': \"heading_order\",\n",
    "             'on_column': \"source\"})),\n",
    "    \n",
    "    ('Replacing image with label', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': replace_image_with_label,\n",
    "             'new_column': \"source\",\n",
    "             'on_column': \"source\"})),\n",
    "    \n",
    "    ('Clearing and parsing source', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': text_preprocessing,\n",
    "             'new_column': \"source_clean\",\n",
    "             'on_column': \"source\"})),\n",
    "    \n",
    "    ('Spelling', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': correct_spelling,\n",
    "             'new_column': \"source_clean\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "    \n",
    "    ('Entities', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "         'func': collect_entities,\n",
    "         'new_column': \"entities\",\n",
    "         'on_column': \"source_clean\"})),\n",
    "    \n",
    "    ('ML glossary feature', FunctionTransformer(\n",
    "         func=prepare_data_with_vector,\n",
    "         kw_args={\n",
    "             'func': get_top_glossary_terms,\n",
    "             'new_column': \"glossary_ml_terms\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "\n",
    "##### COMMENT FOR BERT\n",
    "    ('Lemmatizing sentences', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lemm_sentence,\n",
    "             'new_column': \"source_clean\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## code pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### code comments pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def pipe_code df df prepare_data df tokenize_python_code_names df prepare_data df tokenize_python_code_comments return df'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_python_code_names(\"\"\"\n",
    "def pipe_code(df):\n",
    "    df = prepare_data(df, tokenize_python_code_names, \"code_comments\") # variable names\n",
    "    df = prepare_data(df, tokenize_python_code_comments, \"code_comments\")\n",
    "    \n",
    "    return df\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## FLAGS TODO\n",
    "if there is a function, class\n",
    "counter of \"=\" assignments\n",
    "check if there is a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_code(df):\n",
    "    df = prepare_data(df, tokenize_python_code_names, \"code_variable_names\")\n",
    "    df = prepare_data(df, tokenize_python_code_comments, \"code_comments\")\n",
    "    df = prepare_data(df, text_preprocessing, \"code_comments\", \"code_comments\")\n",
    "    df = prepare_data(df, correct_spelling, \"code_comments\", \"code_comments\")\n",
    "    df = prepare_data(df, correct_spelling, \"code_comments\", \"code_comments\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipe_stats(df):\n",
    "    # length\n",
    "    df = prepare_data(df, lambda x: len(str(x)), \"len_text\")\n",
    "    df = prepare_data(df, lambda x: len(str(x)), \"len_code_comments\")\n",
    "    \n",
    "    # word count\n",
    "    df = prepare_data(df, lambda x: len(str(x).split()), \"count_text\")\n",
    "    df = prepare_data(df, lambda x: len(str(x).split()), \"count_comments\")\n",
    "    df = prepare_data(df, lambda x: len(str(x).split()), \"code_variable_names\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "code_comments_sub_pipeline = Pipeline([\n",
    "    \n",
    "    ('[comments] Extracting code comments', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': tokenize_python_code_comments,\n",
    "             'new_column': \"code_comments\",\n",
    "             'on_column': \"source\"})),\n",
    "    \n",
    "    ('[comments] Clearing and parsing code comments', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': text_preprocessing,\n",
    "             'new_column': \"code_comments\",\n",
    "             'on_column': \"code_comments\"})),\n",
    "    \n",
    "    ('[comments] Correcting spelling', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': correct_spelling,\n",
    "             'new_column': \"code_comments\",\n",
    "             'on_column': \"code_comments\"})),\n",
    "    \n",
    "    ('[comments] Lemmatizing code comments', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lemm_sentence,\n",
    "             'new_column': \"code_comments\",\n",
    "             'on_column': \"code_comments\"})),\n",
    "        # todo make comments statistics and implement it if column is not empty\n",
    "    \n",
    "    ('[comments] Len of code comments', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lambda x: len(str(x).split()),\n",
    "             'new_column': \"len_of_code_comments\",\n",
    "             'on_column': \"code_comments\"})),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### code pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_pipeline = Pipeline([\n",
    "    ('Clearing and parsing source', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': code_preprocessing,\n",
    "             'new_column': \"source_clean\",  # TODO maybe even remove it or leave the same. check on gridsearch later\n",
    "             'on_column': \"source\"})),\n",
    "    \n",
    "    ('Extacting code names', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': tokenize_python_code_names,\n",
    "             'new_column': \"python_code_names\",\n",
    "             'on_column': \"source\"})),\n",
    "    \n",
    "    ('Comments', code_comments_sub_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## counting features pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stats_pipeline = Pipeline([\n",
    "    ('Length', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lambda x: len(str(x).split()),\n",
    "             'new_column': \"text_len\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "    ('Word count', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lambda x: len(str(x)),\n",
    "             'new_column': \"text_word_count\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pipeline helper func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df['index_col'] = range(1, len(df) + 1)  # to merge later\n",
    "    \n",
    "    # splitting on markdown and code\n",
    "    markdowns = df[df['cell_type'] == 'markdown'].reset_index()\n",
    "    codes = df[df['cell_type'] == 'code'].reset_index()\n",
    "\n",
    "    print(f\"Df shape is {df.shape} markdowns {markdowns.shape} code {codes.shape}\")\n",
    "    \n",
    "    markdowns = markdowns_pipeline.fit_transform(markdowns)\n",
    "    markdowns = stats_pipeline.fit_transform(markdowns)\n",
    "    codes = code_pipeline.fit_transform(codes)\n",
    "    codes = stats_pipeline.fit_transform(codes)\n",
    "    \n",
    "    # setting rank\n",
    "    codes['rank'] = codes.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1\n",
    "    markdowns['rank'] = 0\n",
    "\n",
    "    # Stacking back together\n",
    "    df = pd.concat([codes, markdowns]).set_index(['id', 'cell_id', 'index_col'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot insert index_col, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-05557109ae11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-81-952b004f451a>\u001b[0m in \u001b[0;36mpreprocess_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# splitting on markdown and code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmarkdowns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cell_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'markdown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cell_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'code'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   4707\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4708\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4709\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4711\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3590\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3591\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3593\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot insert {}, already exists\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert index_col, already exists"
     ]
    }
   ],
   "source": [
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.to_csv(\"after_pipe.csv\") \n",
    "# load previosly saved df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVALID = 0.1\n",
    "\n",
    "ids = df.index.unique('id')\n",
    "ancestors = get_ancestors(data_dir, ids)\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "ids_train, ids_valid = next(splitter.split(ids, groups=ancestors)) \n",
    "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
    "df_train = df.loc[ids_train, :].sort_index(level='index_col')\n",
    "df_valid = df.loc[ids_valid, :].sort_index(level='index_col')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transforming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFID_FEATURES = {\n",
    "    'entities': None,\n",
    "    # \"glossary_ml_terms\": None,\n",
    "    \"python_code_names\": None,\n",
    "    \"code_comments\": None,\n",
    "    \"source_clean\": None,\n",
    "} # todo gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_cols = [x for x in df.columns if x.startswith(\"glossary_ml_terms\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_vals = scipy.sparse.csr_matrix(df_train[terms_cols].fillna(0.0).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a1527f9e0f4b3a84eef879b601e090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New entities vector TFID (42429, 7)\n",
      "New python_code_names vector TFID (42429, 104)\n",
      "New code_comments vector TFID (42429, 35)\n",
      "New source_clean vector TFID (42429, 214)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfid_transformers = {}\n",
    "vector_shapes = []\n",
    "X_train = np.array([])\n",
    "for feature, max_n in tqdm(TFID_FEATURES.items()):\n",
    "    tfid_tr, tfid_vector = convert_to_TfidfVector(df_train[feature], max_n)\n",
    "    vector_shapes.extend(tfid_vector.shape[1]*[feature])\n",
    "    print(f\"New {feature} vector TFID {tfid_vector.shape}\")\n",
    "    tfid_transformers[feature] = tfid_tr\n",
    "    if not X_train.shape[0]:\n",
    "        X_train = tfid_vector\n",
    "    else:\n",
    "        X_train = sparse.hstack((X_train, tfid_vector))\n",
    "\n",
    "X_train = sparse.hstack((\n",
    "    X_train, \n",
    "    np.where(\n",
    "        df_train['cell_type'] == 'code',\n",
    "        df_train.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.hstack((\n",
    "    X_train, \n",
    "    terms_vals\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank of each cell within the notebook\n",
    "y_train = df_ranks.loc[ids_train].to_numpy()\n",
    "# Number of cells in each notebook\n",
    "groups = df_ranks.loc[ids_train].groupby('id').size().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRanker(base_score=0.5, booster='gbtree', callbacks=None, colsample_bylevel=1,\n",
       "          colsample_bynode=1, colsample_bytree=1, early_stopping_rounds=None,\n",
       "          enable_categorical=False, eval_metric=None, gamma=0, gpu_id=-1,\n",
       "          grow_policy='depthwise', importance_type=None,\n",
       "          interaction_constraints='', learning_rate=0.300000012, max_bin=256,\n",
       "          max_cat_to_onehot=4, max_delta_step=0, max_depth=6, max_leaves=0,\n",
       "          min_child_weight=10, missing=nan, monotone_constraints='()',\n",
       "          n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "          objective='rank:pairwise', predictor='auto', random_state=0,\n",
       "          reg_alpha=0, ...)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRanker\n",
    "\n",
    "model = XGBRanker(\n",
    "    min_child_weight=10,\n",
    "    subsample=0.5,\n",
    "    tree_method='hist',\n",
    ")\n",
    "model.fit(X_train, y_train, group=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7978392663446abea25f2c5226101b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_valid = np.array([])\n",
    "for feature, _ in tqdm(TFID_FEATURES.items()):\n",
    "    transformer = tfid_transformers[feature]\n",
    "    tfid_vector = transformer.transform(df_valid[feature].astype('str'))\n",
    "    if not X_valid.shape[0]:\n",
    "        X_valid = tfid_vector\n",
    "    else:\n",
    "        X_valid = sparse.hstack((X_valid, tfid_vector))\n",
    "\n",
    "X_valid = sparse.hstack((\n",
    "    X_valid, \n",
    "    np.where(\n",
    "        df_valid['cell_type'] == 'code',\n",
    "        df_valid.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_vals = scipy.sparse.csr_matrix(df_valid[terms_cols].fillna(0.0).values)\n",
    "X_valid = sparse.hstack((\n",
    "    X_valid, \n",
    "    terms_vals\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = df_orders.loc[ids_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame({'rank': model.predict(X_valid)}, index=df_valid.index)\n",
    "y_pred = (\n",
    "    y_pred\n",
    "    .sort_values(['id', 'rank'])  # Sort the cells in each notebook by their rank.\n",
    "                                  # The cell_ids are now in the order the model predicted.\n",
    "    .reset_index('cell_id')  # Convert the cell_id index into a column.\n",
    "    .groupby('id')['cell_id'].apply(list)  # Group the cell_ids for each notebook into a list.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.283291481553023"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dummy = df_valid.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
    "kendall_tau(y_valid, y_dummy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39578134054471703"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_tau(y_valid, y_pred)\n",
    "# 0.395 on 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3743558045199923"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_tau(y_valid, y_pred) # 0.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_shapes.extend(terms_cols)\n",
    "\n",
    "vector_shapes = np.array(vector_shapes)\n",
    "\n",
    "features_importance = model.feature_importances_[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature vector glossary_ml_terms_0 \n",
      "validation -> 0.016306407749652863\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_71 \n",
      "dashboard -> 0.005712929181754589\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_39 \n",
      "adam_optimization -> 0.0053808619268238544\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "kaggle -> 0.005372083745896816\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "link -> 0.005234787240624428\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "missing -> 0.005044576246291399\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "out -> 0.005032229702919722\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_212 \n",
      "independent_variable -> 0.004935173783451319\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_153 \n",
      "response_variable -> 0.004728739615529776\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_136 \n",
      "ordinal_variable -> 0.004659112077206373\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_72 \n",
      "dbscan -> 0.004592064302414656\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "notebook -> 0.004560662433505058\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_159 \n",
      "spatial_temporal_reasoning -> 0.004516594111919403\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_90 \n",
      "ggplot2 -> 0.004498551599681377\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_93 \n",
      "gradient_descent -> 0.004459896590560675\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_238 \n",
      "optimizing_for_response_rate -> 0.0043992712162435055\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_9 \n",
      "Quick, Unbiased, Efficient Statistical Tree algorithm\n",
      "(QUEST) -> 0.004376329947263002\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_208 \n",
      "predictive_maintenance -> 0.0042726327665150166\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "also -> 0.004253946710377932\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_158 \n",
      "smote -> 0.0042108637280762196\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_74 \n",
      "descriptive_statistics -> 0.004195813555270433\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "best -> 0.004171708598732948\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "first -> 0.004167480859905481\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_55 \n",
      "concordant_discordant_ratio -> 0.004160747863352299\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_134 \n",
      "one_shot_learning -> 0.0041274866089224815\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "result -> 0.0040791830979287624\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "error -> 0.004058461636304855\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_229 \n",
      "pairing_test -> 0.004046528600156307\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_21 \n",
      "linear regression -> 0.003990857396274805\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_193 \n",
      "real_time_deployment -> 0.003984482958912849\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_29 \n",
      "data quality -> 0.003941861446946859\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "model -> 0.003936899825930595\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_149 \n",
      "recommendation_engine -> 0.0038898135535418987\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_49 \n",
      "bootstrapping -> 0.003882001619786024\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_23 \n",
      "heat map -> 0.003870702814310789\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_111 \n",
      "logistic_regression -> 0.003840838558971882\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_52 \n",
      "business_intelligence -> 0.0038394546136260033\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_99 \n",
      "hyperparameter -> 0.003837746335193515\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_128 \n",
      "naive_bayes -> 0.0038230896461755037\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_148 \n",
      "pytorch -> 0.003791745053604245\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_195 \n",
      "the_data_effect -> 0.003779466962441802\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_80 \n",
      "early_stopping -> 0.0037702121771872044\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_152 \n",
      "residual -> 0.0037388403434306383\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_7 \n",
      "regression tree algorithm -> 0.0037308880127966404\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_141 \n",
      "pattern_recognition -> 0.003729256335645914\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_43 \n",
      "bar_chart -> 0.0037029762752354145\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_61 \n",
      "cosine_similarity -> 0.00366881862282753\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "you -> 0.0035971004981547594\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_36 \n",
      "batch scoring -> 0.003578473348170519\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_244 \n",
      "explainable_machine_learning -> 0.003573119640350342\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "id -> 0.0035658699925988913\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "predict -> 0.003547854721546173\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "some -> 0.00354440207593143\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "same -> 0.003513349685817957\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_197 \n",
      "churn_modeling -> 0.0035094975028187037\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_65 \n",
      "cross_validation -> 0.0034922449849545956\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "regression -> 0.003487419569864869\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "how -> 0.003486370900645852\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "many -> 0.003462303662672639\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_185 \n",
      "unsupervised_machine_learning -> 0.0034603492822498083\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_67 \n",
      "data_science -> 0.003458646358922124\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_50 \n",
      "box_plot -> 0.0034541101194918156\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_163 \n",
      "statistics -> 0.0034265166614204645\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_121 \n",
      "ml_as_a_service_(mlaas) -> 0.003405796829611063\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "analysis -> 0.0033971110824495554\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "other -> 0.0033794643823057413\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "see -> 0.003368632635101676\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "add -> 0.0033627874217927456\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_192 \n",
      "offline_deployment -> 0.003359573893249035\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_75 \n",
      "dependent_variable -> 0.0033360894303768873\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_156 \n",
      "rotational_invariance -> 0.003334341337904334\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_102 \n",
      "imputation -> 0.0033094147220253944\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_240 \n",
      "protected_class -> 0.0033053583465516567\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_164 \n",
      "stochastic_gradient_descent -> 0.0033029362093657255\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_120 \n",
      "mis -> 0.0032684362959116697\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_79 \n",
      "dummy_variable -> 0.0032584501896053553\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_177 \n",
      "z_test -> 0.003226826898753643\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "word -> 0.0032093895133584738\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_30 \n",
      "cross-validation -> 0.003208893584087491\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_53 \n",
      "autoregression -> 0.0032004318200051785\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_188 \n",
      "machine_learning_application -> 0.003199884667992592\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "or -> 0.003188784932717681\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_179 \n",
      "predictive_analytics -> 0.0031447464134544134\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_227 \n",
      "profit_curve -> 0.003133974736556411\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_27 \n",
      "data visualization -> 0.003129372838884592\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_189 \n",
      "deployment -> 0.003111032536253333\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_232 \n",
      "kpi -> 0.0031095994636416435\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_206 \n",
      "predictive_policing -> 0.0031095328740775585\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_63 \n",
      "covariance -> 0.003093244507908821\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "now -> 0.0030858225654810667\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_96 \n",
      "hive -> 0.0030704892706125975\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_209 \n",
      "image_classification -> 0.003064861288294196\n",
      "------------------------------\n",
      "feature vector entities \n",
      "person -> 0.0030493123922497034\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_226 \n",
      "gains_curve -> 0.003029352519661188\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_76 \n",
      "degree_of_freedom -> 0.0030286679975688457\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_247 \n",
      "predatory_micro_targeting -> 0.003027863334864378\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_167 \n",
      "torch -> 0.0030158213339746\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_187 \n",
      "data_science_/_big_data_/_analytics_/_data_mining -> 0.0030139582231640816\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "only -> 0.0030108175706118345\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_82 \n",
      "etl -> 0.0029689385555684566\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "top -> 0.002965689869597554\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_35 \n",
      "Bayesian network -> 0.0029564714059233665\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_201 \n",
      "fraud_detection -> 0.0029482641257345676\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "an -> 0.0029480205848813057\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_143 \n",
      "pig -> 0.002947236644104123\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_68 \n",
      "database -> 0.0029279610607773066\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "describe -> 0.002927306806668639\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_81 \n",
      "eda -> 0.0029188119806349277\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "do -> 0.002909547183662653\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "which -> 0.002898240927606821\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "cv -> 0.002897974569350481\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "this -> 0.0028949195984750986\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "our -> 0.002889147726818919\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_145 \n",
      "principal_component_analysis_(pca) -> 0.002885828958824277\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_169 \n",
      "true_negative -> 0.0028665445279330015\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_58 \n",
      "convergence -> 0.00285791396163404\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "column -> 0.0028543376829475164\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_33 \n",
      "classification and regression tree algorithm -> 0.0028510536067187786\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "rate -> 0.002848283154889941\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_37 \n",
      "association -> 0.002848139265552163\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "data -> 0.0028356430120766163\n",
      "------------------------------\n",
      "feature vector entities \n",
      "ordinal -> 0.0028137871995568275\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "python -> 0.002804085612297058\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "dataset -> 0.002793681574985385\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "isnull -> 0.002782539464533329\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_114 \n",
      "mapreduce -> 0.00276037841103971\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_194 \n",
      "the_prediction_effect -> 0.002756125293672085\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_28 \n",
      "data set -> 0.002732759341597557\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "price -> 0.002726880135014653\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_155 \n",
      "root_mean_squared_error_(rmse) -> 0.002725086407735944\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_151 \n",
      "regularization -> 0.002705731661990285\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_115 \n",
      "market_basket_analysis -> 0.0027043300215154886\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_66 \n",
      "data_mining -> 0.002682659076526761\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "validation -> 0.002658036071807146\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_147 \n",
      "python -> 0.0026575466617941856\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_34 \n",
      "binomial logistic regression -> 0.0026560837868601084\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_122 \n",
      "mode -> 0.0026396040339022875\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "num -> 0.002621912630274892\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "more -> 0.002608782146126032\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "max -> 0.0026045844424515963\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "so -> 0.002599607687443495\n",
      "------------------------------\n",
      "feature vector entities \n",
      "gpe -> 0.0025963878724724054\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "example -> 0.0025877521838992834\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "here -> 0.0025816482957452536\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_60 \n",
      "correlation -> 0.0025713532231748104\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "accuracy -> 0.002563280751928687\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "age -> 0.0025621040258556604\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "y_pred -> 0.0025452501140534878\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "most -> 0.002544335788115859\n",
      "------------------------------\n",
      "feature vector entities \n",
      "date -> 0.002541866386309266\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "distribution -> 0.002534668892621994\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_14 \n",
      "online scoring -> 0.0025297063402831554\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "col -> 0.002529011107981205\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "any -> 0.0025278578978031874\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_89 \n",
      "gated_recurrent_unit_(gru) -> 0.002520219888538122\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_85 \n",
      "false_positive -> 0.0025110698770731688\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "col -> 0.0024924143217504025\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_230 \n",
      "auc -> 0.0024821592960506678\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "each -> 0.002459251321852207\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "title -> 0.0024570836685597897\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_110 \n",
      "log_loss -> 0.0024471876677125692\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_109 \n",
      "line_chart -> 0.00241706776432693\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "unique -> 0.0023790989071130753\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_138 \n",
      "overfitting -> 0.002362394705414772\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_108 \n",
      "labeled_data -> 0.0023581141140311956\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_196 \n",
      "response_modeling -> 0.002345023211091757\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "range -> 0.002337341895326972\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "load -> 0.0023360669147223234\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "like -> 0.00232564564794302\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "step -> 0.0023092760238796473\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "create -> 0.002306784503161907\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_98 \n",
      "holt_winters_forecasting -> 0.0023053407203406096\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "used -> 0.0022969855926930904\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_231 \n",
      "roc -> 0.0022848567459732294\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "them -> 0.002281982684507966\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_38 \n",
      "accuracy -> 0.002279066015034914\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_223 \n",
      "decision_boundaries -> 0.0022687301971018314\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "column -> 0.0022613948676735163\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "predict -> 0.0022599410731345415\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "copy -> 0.002243210095912218\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_162 \n",
      "standard_error -> 0.0022320065181702375\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_119 \n",
      "median -> 0.002229847479611635\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "size -> 0.0022232213523238897\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "score -> 0.002188245067372918\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_31 \n",
      "Cox regression algorithm -> 0.0021818887908011675\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_83 \n",
      "factor_analysis -> 0.0021808184683322906\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "using -> 0.0021789653692394495\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_47 \n",
      "binary_variable -> 0.002176785608753562\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "title -> 0.002174974884837866\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "fit -> 0.0021606069058179855\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_51 \n",
      "business_analytics -> 0.0021448819898068905\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "be -> 0.002142843557521701\n",
      "------------------------------\n",
      "feature vector entities \n",
      "cardinal -> 0.0021254417952150106\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "batch -> 0.0021226569078862667\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "test -> 0.0021190375555306673\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_234 \n",
      "is_possible_to_estimate_a_priori -> 0.002113285241648555\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_3 \n",
      "training -> 0.0021114840637892485\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_228 \n",
      "misclassification_cost -> 0.00209833518601954\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "value -> 0.002095577772706747\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "confusion -> 0.0020926636643707752\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "append -> 0.0020730565302073956\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "new -> 0.0020663507748395205\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_154 \n",
      "roc_auc -> 0.002049048198387027\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_173 \n",
      "t_test -> 0.0020452409517019987\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_25 \n",
      "decision tree algorithm -> 0.0020303837954998016\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_126 \n",
      "multivariate_analysis -> 0.0020272890105843544\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "time -> 0.002027190290391445\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_129 \n",
      "natural_language_processing -> 0.002025763737037778\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_105 \n",
      "iteration -> 0.0020197199191898108\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "with -> 0.0020160849671810865\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "ax -> 0.00201570731587708\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "append -> 0.0020138125400990248\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_220 \n",
      "uplift_modeling_predictive_modeling -> 0.0020077363587915897\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_180 \n",
      "predictive_model -> 0.0020036809146404266\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "display -> 0.0019993723835796118\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "it -> 0.001992761390283704\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "loss -> 0.0019925350788980722\n",
      "------------------------------\n",
      "feature vector entities \n",
      "org -> 0.001992373261600733\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_216 \n",
      "demographic_data -> 0.001981183420866728\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_124 \n",
      "monte_carlo_simluation -> 0.001978538231924176\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "ylabel -> 0.001975047867745161\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "inplace -> 0.0019746681209653616\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "train -> 0.001965251751244068\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_86 \n",
      "feature_reduction -> 0.001960559980943799\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "sklearn -> 0.001957998378202319\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "pyplot -> 0.0019555664621293545\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "matrix -> 0.0019516623578965664\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "if -> 0.001950302510522306\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "plot -> 0.0019502324284985662\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "dataset -> 0.0019446895457804203\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "model -> 0.0019423135090619326\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_130 \n",
      "nosql -> 0.0019401796162128448\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "pred -> 0.0019315503304824233\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "labels -> 0.001907155616208911\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "fig -> 0.0018940296722576022\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "split -> 0.001888210535980761\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_54 \n",
      "computer_vision -> 0.0018842238932847977\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_91 \n",
      "go -> 0.001881820964626968\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_171 \n",
      "type_i_error -> 0.0018792966147884727\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "df -> 0.0018730555893853307\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "value -> 0.0018687844276428223\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "can -> 0.0018682320369407535\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_17 \n",
      "model building -> 0.0018582841148599982\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_4 \n",
      "testing -> 0.0018580324249342084\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_217 \n",
      "behavioral_data -> 0.0018579972675070167\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "color -> 0.0018547277431935072\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "plot -> 0.0018529595108702779\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "output -> 0.0018452914664521813\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "no -> 0.001840865472331643\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "will -> 0.0018365061841905117\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "year -> 0.0018210153793916106\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_10 \n",
      "probability -> 0.0018134349957108498\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "make -> 0.0018011280335485935\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "label -> 0.0018003388540819287\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "this -> 0.0017899498343467712\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "false -> 0.0017813232261687517\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "sns -> 0.0017809863202273846\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_170 \n",
      "true_positive -> 0.0017784432275220752\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_183 \n",
      "labeled_data_training_data -> 0.0017739926697686315\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "variable -> 0.00176629435736686\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "ha -> 0.0017586909234523773\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_137 \n",
      "outlier -> 0.0017584513407200575\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "will -> 0.001741712330840528\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_94 \n",
      "hadoop -> 0.001730986637994647\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "path -> 0.0017292846459895372\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "get -> 0.0017169754719361663\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "cmap -> 0.0017120070988312364\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "apply -> 0.0017027423018589616\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "np -> 0.0016993589233607054\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_199 \n",
      "credit_scoring -> 0.0016853843117132783\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "data -> 0.0016818594885990024\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_242 \n",
      "machine_bias -> 0.0016814154805615544\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "file -> 0.001675583072938025\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_166 \n",
      "tokenization -> 0.0016724667511880398\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_245 \n",
      "model_transparency -> 0.001671390957199037\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_56 \n",
      "confidence_interval -> 0.0016620911192148924\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "train_df -> 0.0016610994935035706\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "ax -> 0.0016462564235553145\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "function -> 0.0016404205234721303\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "inplace -> 0.0016361779998987913\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_248 \n",
      "the_coded_gaze -> 0.0016179131343960762\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_146 \n",
      "p_value -> 0.0016135904006659985\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "fontsize -> 0.0016090755816549063\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_191 \n",
      "decision_support -> 0.0016021985793486238\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "final -> 0.0015933760441839695\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "that -> 0.0015918760327622294\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "list -> 0.0015885489992797375\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "range -> 0.0015875016106292605\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "random -> 0.001587413251399994\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "use -> 0.00158269377425313\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_203 \n",
      "ad_targeting -> 0.0015675077447667718\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "ascending -> 0.0015663900412619114\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "train -> 0.001565976650454104\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "return -> 0.0015577094163745642\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_219 \n",
      "feature_selection -> 0.0015559298917651176\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "show -> 0.0015514055266976357\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "csv -> 0.0015502114547416568\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "with -> 0.00154744868632406\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "input -> 0.0015472632367163897\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "index -> 0.0015468500787392259\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "for -> 0.0015365798026323318\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "on -> 0.0015332474140450358\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "feature -> 0.0015282992972061038\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "are -> 0.0015254402533173561\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "sort_values -> 0.0015197083121165633\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "is -> 0.0015191661659628153\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "linear -> 0.0015169150428846478\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "counts -> 0.001516609569080174\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "values -> 0.001516050542704761\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "for -> 0.0015110953245311975\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "of -> 0.0015072955284267664\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "figure -> 0.0015032461378723383\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "show -> 0.0015009600901976228\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "list -> 0.0014944338472560048\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "let -> 0.0014930664328858256\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "apply -> 0.001490807393565774\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "all -> 0.0014899799134582281\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "imshow -> 0.0014889718731865287\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "str -> 0.0014861655654385686\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "sum -> 0.0014843178214505315\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "df -> 0.0014758734032511711\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "by -> 0.0014728934038430452\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_168 \n",
      "transfer_learning -> 0.0014726845547556877\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "data -> 0.001467126072384417\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "loc -> 0.0014647877542302012\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "and -> 0.0014491607435047626\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_40 \n",
      "apache_spark -> 0.0014489792520180345\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "there -> 0.0014420924708247185\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "columns -> 0.0014410114381462336\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_1 \n",
      "unrefined model -> 0.0014403671957552433\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "number -> 0.001439305953681469\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "value_counts -> 0.0014365093084052205\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "preprocessing -> 0.0014229746302589774\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "len -> 0.00142085540574044\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "sns -> 0.0014142390573397279\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "text -> 0.00141394033562392\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "import -> 0.0014078703243285418\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "features -> 0.0014052652986720204\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "if -> 0.0013928060652688146\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "from -> 0.0013923232909291983\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "drop -> 0.001390227465890348\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "figsize -> 0.0013870825059711933\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "pd -> 0.001381924725137651\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "figsize -> 0.001378518296405673\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "train_data -> 0.0013770540244877338\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "test -> 0.0013764383038505912\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "loc -> 0.0013734097592532635\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_211 \n",
      "predictive_goal -> 0.0013732768129557371\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_181 \n",
      "n_individual -> 0.0013607700821012259\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "columns -> 0.001358174835331738\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "path -> 0.0013577251229435205\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_132 \n",
      "normalization -> 0.001355145825073123\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "to -> 0.0013546079862862825\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "fit -> 0.0013496262254193425\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "x_test -> 0.0013441652990877628\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "true -> 0.001343411160632968\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "import -> 0.0013370459200814366\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "we -> 0.001331849955022335\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "x_train -> 0.001323804841376841\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "return -> 0.0013210419565439224\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "dataframe -> 0.0013197551015764475\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "false -> 0.0013176666107028723\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "fig -> 0.0013092505978420377\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_172 \n",
      "type_ii_error -> 0.0012937618885189295\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "into -> 0.0012934013502672315\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "index -> 0.0012923061149194837\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "class -> 0.0012910979567095637\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "at -> 0.0012870486825704575\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "test -> 0.0012843667063862085\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "np -> 0.0012604567455127835\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "from -> 0.0012531070969998837\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "lambda -> 0.0012501688906922936\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "label -> 0.0012489573564380407\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_190 \n",
      "decision_automation -> 0.0012419294798746705\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "mean -> 0.0012363312998786569\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "it -> 0.0012329757446423173\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "legend -> 0.0012303140247240663\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_77 \n",
      "dimensionality_reduction -> 0.0012271006125956774\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "groupby -> 0.0012249764986336231\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "plt -> 0.0012077196734026074\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "and -> 0.0011925837025046349\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_241 \n",
      "discriminatory_model -> 0.0011874389601871371\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "number -> 0.0011873035691678524\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "dataframe -> 0.0011799463536590338\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "iloc -> 0.0011797993211075664\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "values -> 0.0011792548466473818\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "metrics -> 0.0011785413371399045\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "is -> 0.001169094117358327\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "head -> 0.0011537853861227632\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "set -> 0.0011411134619265795\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "image -> 0.0011359085328876972\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "isnull -> 0.0011314927833154798\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_87 \n",
      "flume -> 0.0011260133469477296\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "def -> 0.0011259092716500163\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "in -> 0.0011255774879828095\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "sum -> 0.001121720764786005\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "table -> 0.001111589721404016\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "figure -> 0.001098458538763225\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "axis -> 0.0010969274444505572\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "read_csv -> 0.0010910710552707314\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "all -> 0.0010906425304710865\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "from -> 0.0010883375070989132\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "the -> 0.0010493374429643154\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "training -> 0.0010417932644486427\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "to -> 0.0010414085118100047\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "true -> 0.0010410200338810682\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_69 \n",
      "dataframe -> 0.0010337064741179347\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "print -> 0.001031956635415554\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "shape -> 0.0010249415645375848\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "head -> 0.001014644862152636\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "in -> 0.0010145466076210141\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "model -> 0.0010102881351485848\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "axis -> 0.0010054103331640363\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "list -> 0.0009983344934880733\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "groupby -> 0.0009862175211310387\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "split -> 0.0009757500374689698\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "of -> 0.0009356533410027623\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "def -> 0.0008980240672826767\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "shape -> 0.0008978588739410043\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "pd -> 0.000895101111382246\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "random_state -> 0.0008929639006964862\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "os -> 0.0008805913385003805\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "print -> 0.0008776640170253813\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "than -> 0.0008772742585279047\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "as -> 0.0008584195747971535\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "os -> 0.0008306889794766903\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "val -> 0.00082910101627931\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "plt -> 0.0008278816239908338\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "size -> 0.000819484586827457\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "xlabel -> 0.0008186984341591597\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "the -> 0.0008108200272545218\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "model_selection -> 0.0008034125785343349\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "y_test -> 0.00079496786929667\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "target -> 0.0007937658810988069\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "read -> 0.000755522632971406\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_139 \n",
      "pandas -> 0.0007549882284365594\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "pandas -> 0.0007280503632500768\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_243 \n",
      "ground_truth. -> 0.0007164666894823313\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "y_train -> 0.0007130114827305079\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_133 \n",
      "numpy -> 0.0007090349681675434\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "pandas -> 0.0006978574092499912\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "prediction -> 0.0006921064341440797\n",
      "------------------------------\n",
      "feature vector entities \n",
      "nan -> 0.0006235036416910589\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "drop -> 0.0006083844345994294\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_165 \n",
      "tensorflow -> 0.0005716949817724526\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_200 \n",
      "insurance_pricing_and_selection -> 0.0005428330041468143\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_184 \n",
      "supervised_machine_learning_machine_learning -> 0.0004455843009054661\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "accuracy_score -> 0.00037137657636776567\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_210 \n",
      "data_preparation -> 0.0003651343868114054\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "selection -> 0.0003155431186314672\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "classification -> 0.00024241683422587812\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "metrics -> 0.00016447865345980972\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_127 \n",
      "multivariate_regression -> 0.00016263878205791116\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "matplotlib -> 0.0001480139180785045\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "describe -> 0.00012128637172281742\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_84 \n",
      "false_negative -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "create -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "csv -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "are -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "none -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "feature -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "preprocessing -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "image -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_97 \n",
      "holdout_sample -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_95 \n",
      "hidden_markov_model -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "by -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_92 \n",
      "goodness_of_fit -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "nan -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_78 \n",
      "dplyr -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "sklearn -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_88 \n",
      "f_score -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "subplots -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_8 \n",
      "regression -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "int -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "mean -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "join -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "else -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "astype -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "keras -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "seaborn -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "kind -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "labels -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "reset_index -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "train_test_split -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "format -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "file -> 0.0\n",
      "------------------------------\n",
      "feature vector python_code_names \n",
      "numpy -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_157 \n",
      "scala -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "for -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_222 \n",
      "deduction -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_103 \n",
      "inferential_statistics -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_198 \n",
      "workforce_churn_modeling -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_101 \n",
      "hypothesis -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_100 \n",
      "hyperplane -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_2 \n",
      "transformation -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_20 \n",
      "linear regression model -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "what -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_202 \n",
      "product_recommendations -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_204 \n",
      "non_profit_fundraising -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "type -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "transform -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "total -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_205 \n",
      "algorithmic_trading -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_207 \n",
      "fault_detection -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "these -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "text -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "subplots -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "state -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "sort -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_213 \n",
      "binary_classifier. -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_214 \n",
      "positive_and_negative_examples. -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_215 \n",
      "test_data -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "seaborn -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "sample -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_218 \n",
      "derived_variable -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_22 \n",
      "histogram -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "pyplot -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_104 \n",
      "iqr -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_106 \n",
      "julia -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_107 \n",
      "keras -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_13 \n",
      "partition -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_160 \n",
      "standard_deviation -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_161 \n",
      "standardization -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_150 \n",
      "regression_spline -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_15 \n",
      "neural network -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_144 \n",
      "predictor_variable -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_142 \n",
      "pie_chart -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_140 \n",
      "parameters -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_174 \n",
      "underfitting -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_175 \n",
      "univariate_analysis -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_135 \n",
      "oozie -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_176 \n",
      "nan -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_131 \n",
      "nominal_variable -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_178 \n",
      "zookeeper -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_11 \n",
      "Predictive Model Markup Language (PMML) -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_125 \n",
      "multi_class_classification -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_123 \n",
      "model_selection -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_18 \n",
      "misclassification cost -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_12 \n",
      "predictive analytics -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_182 \n",
      "training_data -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_118 \n",
      "mean -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_117 \n",
      "maximum_likelihood_estimation -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_116 \n",
      "market_mix_modeling -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_113 \n",
      "mahout -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_112 \n",
      "long_short_term_memory_(lstm) -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_186 \n",
      "forecasting -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_19 \n",
      "logistic regression -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_221 \n",
      "induction -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_224 \n",
      "automl -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "get -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_225 \n",
      "lift -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "count -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "copy -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "color -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "check -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "categorical -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "but -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "between -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "based -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "as -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "array -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_57 \n",
      "continuous_variable -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_59 \n",
      "convex_function -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_6 \n",
      "score -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_62 \n",
      "cost_function -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_64 \n",
      "cross_entropy -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_70 \n",
      "dataset -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "above -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "we -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "using -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "train -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_73 \n",
      "decision_boundary -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "that -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "pd -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "nan -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "input -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "in -> 0.0\n",
      "------------------------------\n",
      "feature vector code_comments \n",
      "image -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_5 \n",
      "script -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_48 \n",
      "boosting -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_46 \n",
      "big_data -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "look -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_233 \n",
      "strategic_objective -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "one -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "numpy -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_235 \n",
      "p_hacking -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_236 \n",
      "the_accuracy_fallacy -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_237 \n",
      "presuming_that_correlation_implies_causation -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "not -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "none -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "name -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_239 \n",
      "data_leak -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_24 \n",
      "evaluate -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "matplotlib -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_246 \n",
      "the_right_to_explanation -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "different -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "len -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "learning -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_26 \n",
      "decision list -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "info -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "img -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_32 \n",
      "confidence score -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "have -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_16 \n",
      "multinomial logistic regression -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_41 \n",
      "backpropogation -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_42 \n",
      "bagging -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_44 \n",
      "bayesian_statistics -> 0.0\n",
      "------------------------------\n",
      "feature vector glossary_ml_terms_45 \n",
      "bias_variance_trade_off -> 0.0\n",
      "------------------------------\n",
      "feature vector source_clean \n",
      "format -> 0.0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "k=10000\n",
    "position_shift = 0\n",
    "for x in features_importance.argsort()[-k:][::-1]:\n",
    "    feature_name = vector_shapes[x]\n",
    "    print(f\"feature vector {feature_name} \")\n",
    "    position_shift = np.where(vector_shapes == feature_name)[0][0]\n",
    "    if \"ml_terms\" in feature_name:\n",
    "        print(\n",
    "            f\"{terms[int(feature_name.split('_')[-1])]} -> {model.feature_importances_[x]}\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"{tfid_transformers[feature_name].get_feature_names()[x-position_shift]} -> \\\n",
    "{model.feature_importances_[x]}\"\n",
    "        )\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
