{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## loading required data and libs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "! pip install kaggle\n",
    "! mkdir ~/.kaggle\n",
    "! cp \"environment/kaggle.json\" ~/.kaggle/\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "! kaggle competitions download -c AI4Code\n",
    "! mkdir data\n",
    "! unzip -n AI4Code.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (3.3.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.7.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.42.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.1.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.28.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.4.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (59.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.6.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy) (2.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy) (2.4.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy) (1.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy==1.19.5 in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: pandas==0.25.3 in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 2)) (0.25.3)\n",
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 3)) (1.6.1)\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 4)) (3.3.1)\n",
      "Requirement already satisfied: contextualSpellCheck in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 5)) (0.4.1)\n",
      "Requirement already satisfied: black in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 6)) (22.6.0)\n",
      "Requirement already satisfied: sentence-transformers in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 7)) (2.2.2)\n",
      "Requirement already satisfied: autocorrect in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 8)) (2.6.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from -r environment/requirenments.txt (line 9)) (4.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3->-r environment/requirenments.txt (line 2)) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3->-r environment/requirenments.txt (line 2)) (2019.3)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from xgboost->-r environment/requirenments.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (2.4.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (2.28.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (0.6.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (0.7.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (1.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (4.42.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (8.0.17)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (1.0.7)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (4.1.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (59.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (0.9.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy->-r environment/requirenments.txt (line 4)) (2.0.6)\n",
      "Requirement already satisfied: editdistance==0.5.3 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck->-r environment/requirenments.txt (line 5)) (0.5.3)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck->-r environment/requirenments.txt (line 5)) (1.12.0)\n",
      "Requirement already satisfied: transformers>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck->-r environment/requirenments.txt (line 5)) (4.20.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.7/site-packages (from black->-r environment/requirenments.txt (line 6)) (2.5.2)\n",
      "Requirement already satisfied: typed-ast>=1.4.2 in /opt/conda/lib/python3.7/site-packages (from black->-r environment/requirenments.txt (line 6)) (1.5.4)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from black->-r environment/requirenments.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from black->-r environment/requirenments.txt (line 6)) (2.0.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from black->-r environment/requirenments.txt (line 6)) (0.4.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from black->-r environment/requirenments.txt (line 6)) (8.1.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers->-r environment/requirenments.txt (line 7)) (0.8.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers->-r environment/requirenments.txt (line 7)) (0.22.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers->-r environment/requirenments.txt (line 7)) (0.13.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers->-r environment/requirenments.txt (line 7)) (3.7)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers->-r environment/requirenments.txt (line 7)) (0.1.96)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->-r environment/requirenments.txt (line 9)) (1.9.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy->-r environment/requirenments.txt (line 4)) (2.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=8.0.0->black->-r environment/requirenments.txt (line 6)) (1.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r environment/requirenments.txt (line 7)) (3.0.12)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers->-r environment/requirenments.txt (line 7)) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy->-r environment/requirenments.txt (line 4)) (2.4.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy->-r environment/requirenments.txt (line 4)) (5.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==0.25.3->-r environment/requirenments.txt (line 2)) (1.14.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r environment/requirenments.txt (line 4)) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r environment/requirenments.txt (line 4)) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r environment/requirenments.txt (line 4)) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r environment/requirenments.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck->-r environment/requirenments.txt (line 5)) (2022.6.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck->-r environment/requirenments.txt (line 5)) (0.12.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy->-r environment/requirenments.txt (line 4)) (2.1.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers->-r environment/requirenments.txt (line 7)) (0.14.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers->-r environment/requirenments.txt (line 7)) (9.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.7/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.20.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.8.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.13.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.22.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.42.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.4.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.96)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (1.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (0.14.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (2.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.12.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.13.0)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.7/site-packages (0.12.0+cpu)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision) (2.28.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (9.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision) (2.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting en-core-web-lg==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.3.0/en_core_web_lg-3.3.0-py3-none-any.whl (400.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-lg==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (21.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (59.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.28.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (4.42.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.19.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.4.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-lg==3.3.0) (1.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n",
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.7/site-packages (from en-core-web-sm==3.3.0) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.1.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.42.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.19.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (59.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.28.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.8)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=7.1.1->typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.5.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Requirement already satisfied: contextualSpellCheck in /opt/conda/lib/python3.7/site-packages (0.4.1)\n",
      "Requirement already satisfied: spacy>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck) (3.3.1)\n",
      "Requirement already satisfied: editdistance==0.5.3 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck) (0.5.3)\n",
      "Requirement already satisfied: transformers>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck) (4.20.1)\n",
      "Requirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from contextualSpellCheck) (1.12.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (1.0.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (3.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (2.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (0.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (4.42.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (21.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (0.4.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (0.6.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (2.28.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (8.0.17)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (3.1.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (1.0.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (0.7.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (59.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (4.1.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy>=3.0.0->contextualSpellCheck) (1.19.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (6.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (0.12.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (1.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (0.8.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers>=4.0.0->contextualSpellCheck) (2022.6.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.6->spacy>=3.0.0->contextualSpellCheck) (2.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->spacy>=3.0.0->contextualSpellCheck) (2.4.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /opt/conda/lib/python3.7/site-packages (from pathy>=0.3.5->spacy>=3.0.0->contextualSpellCheck) (5.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy>=3.0.0->contextualSpellCheck) (2.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.7/site-packages (from typer<0.5.0,>=0.3.0->spacy>=3.0.0->contextualSpellCheck) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->spacy>=3.0.0->contextualSpellCheck) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: autocorrect in /opt/conda/lib/python3.7/site-packages (2.6.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: black in /opt/conda/lib/python3.7/site-packages (22.6.0)\n",
      "Requirement already satisfied: typed-ast>=1.4.2 in /opt/conda/lib/python3.7/site-packages (from black) (1.5.4)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from black) (2.0.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.7/site-packages (from black) (2.5.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from black) (8.1.3)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /opt/conda/lib/python3.7/site-packages (from black) (4.1.1)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/lib/python3.7/site-packages (from black) (0.9.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.7/site-packages (from black) (0.4.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click>=8.0.0->black) (1.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click>=8.0.0->black) (2.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install -U spacy\n",
    "! pip install -U -r environment/requirenments.txt\n",
    "! pip install -U sentence-transformers\n",
    "! pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "! python -m spacy download en_core_web_lg\n",
    "! python -m spacy download en_core_web_sm\n",
    "!pip install contextualSpellCheck\n",
    "!pip install autocorrect\n",
    "!pip install black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import black\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "from autocorrect import Speller\n",
    "import json\n",
    "import inspect\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "# from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import tokenize\n",
    "from tokenize import TokenError\n",
    "import io\n",
    "tqdm.pandas()\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.pipeline import Pipeline\n",
    "import sys\n",
    "import textwrap\n",
    "import wandb\n",
    "import spacy\n",
    "import contextualSpellCheck\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "ner = spacy.load(\"en_core_web_lg\")\n",
    "check_spelling = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "\n",
    "data_dir = Path('data/')\n",
    "sys.path.append(str('AI4Code'))\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "contextualSpellCheck.add_to_pipe(check_spelling)\n",
    "# black_refactroing_mode = black.FileMode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## text utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spell = Speller(fast=True)\n",
    "def correct_spelling(text):\n",
    "    if text:\n",
    "        return spell(text)\n",
    "    else:\n",
    "        return text\n",
    "        \n",
    "\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    if not text:\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = text.strip()\n",
    "    text = ' '.join(text.split())\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\[.*?\\]', ' ', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    Cleaning and parsing the text.\n",
    "\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    nopunc = clean_text(text)\n",
    "    tokenized_text = tokenizer.tokenize(nopunc)\n",
    "    combined_text = ' '.join(tokenized_text)\n",
    "    return combined_text\n",
    "\n",
    "def clean_code(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.replace('[', ' ').replace(']', ' ').replace('(', ' ')\\\n",
    "    .replace(')', ' ').replace('{', ' ').replace('}', ' ').replace('=', ' ').replace(',', ' ')\n",
    "    text = text.lower()\n",
    "    text = text.replace('_', ' ')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('.', ' ')\n",
    "    text = re.sub(r'\".*\"', ' ', text)\n",
    "    text = re.sub(r\"'.*'\", ' ', text)\n",
    "    text = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def code_preprocessing(text):\n",
    "    \"\"\"\n",
    "    Cleaning and parsing the text.\n",
    "\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = black.format_str(text, mode=black_refactroing_mode) ## maybe remove\n",
    "    except:\n",
    "        pass\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    nopunc = clean_code(text)\n",
    "    tokenized_text = tokenizer.tokenize(nopunc)\n",
    "    combined_text = ' '.join(tokenized_text)\n",
    "    return combined_text\n",
    "\n",
    "def count_hastags(row):\n",
    "    \"Count the number of hashtags \"\n",
    "    row['hash_count'] = row['source'].count('# ') if row['cell_type']=='markdown' else 0\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## reading utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]\n",
    "\n",
    "def read_train_data(data_dir, NUM_TRAIN = 10000, OFFSET=0):\n",
    "    def read_notebook(path):\n",
    "        return (\n",
    "            pd.read_json(\n",
    "                path,\n",
    "                dtype={'cell_type': 'category', 'source': 'str'})\n",
    "            .assign(id=path.stem)  # final path component\n",
    "            .rename_axis('cell_id')\n",
    "        )\n",
    "\n",
    "    paths_train = list((data_dir / 'train').glob('*.json'))[OFFSET:NUM_TRAIN]\n",
    "    notebooks_train = [\n",
    "      read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n",
    "    ]\n",
    "    df = (\n",
    "      pd.concat(notebooks_train)\n",
    "      .set_index('id', append=True)\n",
    "      .swaplevel()\n",
    "      .sort_index(level='id', sort_remaining=False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def get_df_orders_and_ranks(df, data_dir):\n",
    "    # train orders\n",
    "    df_orders = pd.read_csv(\n",
    "      data_dir / 'train_orders.csv',\n",
    "      index_col='id',\n",
    "      squeeze=True,\n",
    "    ).str.split()  # cell_ids str -> list\n",
    "\n",
    "\n",
    "    df_orders_ = df_orders.to_frame().join(\n",
    "      # reset only one index out of many -> \"cell_id\"; make a list out of cells in train data\n",
    "      df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "      how='right',\n",
    "    )\n",
    "\n",
    "    ranks = {}\n",
    "    for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "        ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "    df_ranks = (\n",
    "      pd.DataFrame\n",
    "      .from_dict(ranks, orient='index')\n",
    "      .rename_axis('id')\n",
    "      .apply(pd.Series.explode)\n",
    "      .set_index('cell_id', append=True)\n",
    "    )\n",
    "    # now we have\n",
    "    # id cell_id rank\n",
    "    return df_orders, df_ranks\n",
    "\n",
    "\n",
    "def get_ancestors(data_dir, ids):\n",
    "    # Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "    df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n",
    "    return df_ancestors.loc[ids, 'ancestor_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8664c4b30a48a4bb1f087945e5ca09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Train NBs', max=10000.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Df shape is (461582, 2)\n"
     ]
    }
   ],
   "source": [
    "# example pipeline work\n",
    "df = read_train_data(data_dir, NUM_TRAIN=10000)\n",
    "df_orders, df_ranks = get_df_orders_and_ranks(df, data_dir)\n",
    "\n",
    "print(f\"Df shape is {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general columns\n",
    "def prepare_data(df, func, new_column, on_column='source'):\n",
    "    df[new_column] = df.progress_apply(lambda x: func(x[on_column]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## lemmatizer \n",
    "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def tokenize_python_code_names(text):\n",
    "    try:\n",
    "        code_text = tokenize.generate_tokens(io.StringIO(text).readline)\n",
    "        strings = [tok.string for tok in code_text if tok.type==1]\n",
    "    except Exception:\n",
    "        return None # Error happened\n",
    "    return ' '.join(strings)\n",
    "\n",
    "def tokenize_python_code_comments(text):\n",
    "    try:\n",
    "        code_text = tokenize.generate_tokens(io.StringIO(text).readline)\n",
    "        strings = [tok.string for tok in code_text if tok.type==55]\n",
    "    except Exception:\n",
    "        return None # Error happened\n",
    "    return ' '.join(strings)\n",
    "\n",
    "def lemm_sentence(text):\n",
    "    lst_txt = [lem.lemmatize(word) for word in text.split()]\n",
    "    return ' '.join(lst_txt)\n",
    "\n",
    "def collect_entities(text):\n",
    "    \"Named Entity Recognition\"\n",
    "    rs = ner(text)\n",
    "    labels = []\n",
    "    for r in rs.ents:\n",
    "        labels.append(r.label_)\n",
    "    return ' '.join(labels)\n",
    "\n",
    "def convert_to_TfidfVector(df, max_features=100):\n",
    "    tfidf = TfidfVectorizer(min_df=0.01, max_features=max_features)\n",
    "    return tfidf, tfidf.fit_transform(df.astype(str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ALPHA 1 todo list\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# todo analyze the most often misspleled word and create local vocabulary\n",
    "# todo collect the list of tags in machine learning and find it among the most popular words\n",
    "# todo instead of removing the link mark it as a <LINK> symbol or <IMAGE> and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Machine Learning glossary feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "ml_glossary = pd.read_csv(\"machine_learning_glossary_terms.csv\")\n",
    "# sentences we will be searching through\n",
    "corpus = np.array(ml_glossary['definition'])\n",
    "terms = np.array(ml_glossary['term'])\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better do not vector but words and the put them to TFID\n",
    "top_k=6\n",
    "def get_top_glossary_terms(query):\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k, query_chunk_size=1000)\n",
    "    hits = ['_'.join(str(terms[hit['corpus_id']]).split()) for hit in hits[0]]\n",
    "    return ' '.join(hits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## markdowns pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdowns_pipeline = Pipeline([\n",
    "    ('Clearing and parsing source', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': text_preprocessing,\n",
    "             'new_column': \"source_clean\",\n",
    "             'on_column': \"source\"})),\n",
    "    ('Spelling', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': correct_spelling,\n",
    "             'new_column': \"source_clean\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "    ('Entities', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "         'func': collect_entities,\n",
    "         'new_column': \"entities\",\n",
    "         'on_column': \"source_clean\"})),\n",
    "    ('ML glossary feature', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': get_top_glossary_terms,\n",
    "             'new_column': \"glossary_ml_terms\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "    ('Lemmatizing sentences', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lemm_sentence,\n",
    "             'new_column': \"source_clean\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_sub_pipeline = Pipeline([\n",
    "    ('[comments] Extracting code comments', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': tokenize_python_code_comments,\n",
    "             'new_column': \"code_comments\",\n",
    "             'on_column': \"source\"})),\n",
    "    ('[comments] Clearing and parsing code comments', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': text_preprocessing,\n",
    "             'new_column': \"code_comments\",\n",
    "             'on_column': \"code_comments\"})),\n",
    "    ('[comments] Correcting spelling', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': correct_spelling,\n",
    "             'new_column': \"code_comments\",\n",
    "             'on_column': \"code_comments\"})),\n",
    "    ('[comments] Lemmatizing code comments', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lemm_sentence, # todo maybe make additional pipeline for comments and multisteps pipe\n",
    "             'new_column': \"code_comments\",\n",
    "             'on_column': \"code_comments\"})),\n",
    "        # todo make comments statistics and implement it if column is not empty\n",
    "    ('[3] Comments stats', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lambda x: len(str(x).split()),\n",
    "             'new_column': \"len_of_code_comments\",\n",
    "             'on_column': \"code_comments\"})),\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code_pipeline = Pipeline([\n",
    "    ('Clearing and parsing source', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': code_preprocessing,\n",
    "             'new_column': \"source_clean\",  # TODO maybe even remove it or leave the same. check on gridsearch later\n",
    "             'on_column': \"source\"})),\n",
    "    \n",
    "    ('Extacting code names', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': tokenize_python_code_names,\n",
    "             'new_column': \"python_code_names\",\n",
    "             'on_column': \"source\"})),\n",
    "    \n",
    "    ('Comments', comments_sub_pipeline)\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting features\n",
    "stats_pipeline = Pipeline([\n",
    "    ('Length', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lambda x: len(str(x).split()),\n",
    "             'new_column': \"text_len\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "    ('Word count', FunctionTransformer(\n",
    "         func=prepare_data,\n",
    "         kw_args={\n",
    "             'func': lambda x: len(str(x)),\n",
    "             'new_column': \"text_word_count\",\n",
    "             'on_column': \"source_clean\"})),\n",
    "\n",
    "], verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## connecting together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    df['index_col'] = range(1, len(df) + 1)\n",
    "    \n",
    "    # splitting on markdown and code\n",
    "    markdowns = df[df['cell_type'] == 'markdown'].reset_index()\n",
    "    codes = df[df['cell_type'] == 'code'].reset_index()\n",
    "\n",
    "    print(f\"Df shape is {df.shape} markdowns {markdowns.shape} code {codes.shape}\")\n",
    "    \n",
    "    markdowns = markdowns_pipeline.fit_transform(markdowns)\n",
    "    markdowns = stats_pipeline.fit_transform(markdowns)\n",
    "    codes = code_pipeline.fit_transform(codes)\n",
    "    codes = stats_pipeline.fit_transform(codes)\n",
    "    \n",
    "    # setting rank\n",
    "    codes['rank'] = codes.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1\n",
    "    markdowns['rank'] = 0\n",
    "\n",
    "    # Stacking back together\n",
    "    df = pd.concat([codes, markdowns]).set_index(['id', 'cell_id', 'index_col'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape is (461582, 3) markdowns (156444, 5) code (305138, 5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b9ba1eec984cf3b30a1311c24d7fc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=156444.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pipeline]  (step 1 of 5) Processing Clearing and parsing source, total=  11.9s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acfb5cc8b9b47d08cdb090d2065165c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=156444.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Pipeline] .......... (step 2 of 5) Processing Spelling, total= 1.2min\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33b9cf161c941778a8364030b36e29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=156444.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = preprocess_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVALID = 0.1\n",
    "\n",
    "ids = df.index.unique('id')\n",
    "ancestors = get_ancestors(data_dir, ids)\n",
    "splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n",
    "ids_train, ids_valid = next(splitter.split(ids, groups=ancestors)) \n",
    "ids_train, ids_valid = ids[ids_train], ids[ids_valid]\n",
    "df_train = df.loc[ids_train, :].sort_index(level='index_col')\n",
    "df_valid = df.loc[ids_valid, :].sort_index(level='index_col')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFID_FEATURES = {\n",
    "    'entities': None,\n",
    "    \"glossary_ml_terms\": None,\n",
    "    \"python_code_names\": None,\n",
    "    \"code_comments\": None,\n",
    "    \"source_clean\": None,\n",
    "} # todo gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_transformers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([])\n",
    "for feature, max_n in tqdm(TFID_FEATURES.items()):\n",
    "    tfid_tr, tfid_vector = convert_to_TfidfVector(df_train[feature], max_n)\n",
    "    tfid_transformers[feature] = tfid_tr\n",
    "    if not X_train.shape[0]:\n",
    "        X_train = tfid_vector\n",
    "    else:\n",
    "        X_train = sparse.hstack((X_train, tfid_vector))\n",
    "\n",
    "X_train = sparse.hstack((\n",
    "    X_train, \n",
    "    np.where(\n",
    "        df_train['cell_type'] == 'code',\n",
    "        df_train.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank of each cell within the notebook\n",
    "y_train = df_ranks.loc[ids_train].to_numpy()\n",
    "# Number of cells in each notebook\n",
    "groups = df_ranks.loc[ids_train].groupby('id').size().to_numpy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRanker\n",
    "\n",
    "model = XGBRanker(\n",
    "    min_child_weight=10,\n",
    "    subsample=0.5,\n",
    "    tree_method='hist',\n",
    ")\n",
    "model.fit(X_train, y_train, group=groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid_transformers['entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.array([])\n",
    "for feature, _ in tqdm(TFID_FEATURES.items()):\n",
    "    transformer = tfid_transformers[feature]\n",
    "    tfid_vector = transformer.transform(df_valid[feature].astype('str'))\n",
    "    if not X_valid.shape[0]:\n",
    "        X_valid = tfid_vector\n",
    "    else:\n",
    "        X_valid = sparse.hstack((X_valid, tfid_vector))\n",
    "\n",
    "X_valid = sparse.hstack((\n",
    "    X_valid, \n",
    "    np.where(\n",
    "        df_valid['cell_type'] == 'code',\n",
    "        df_valid.groupby(['id', 'cell_type']).cumcount().to_numpy() + 1,\n",
    "        0,\n",
    "    ).reshape(-1, 1)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = df_orders.loc[ids_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame({'rank': model.predict(X_valid)}, index=df_valid.index)\n",
    "y_pred = (\n",
    "    y_pred\n",
    "    .sort_values(['id', 'rank'])  # Sort the cells in each notebook by their rank.\n",
    "                                  # The cell_ids are now in the order the model predicted.\n",
    "    .reset_index('cell_id')  # Convert the cell_id index into a column.\n",
    "    .groupby('id')['cell_id'].apply(list)  # Group the cell_ids for each notebook into a list.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "\n",
    "\n",
    "def count_inversions(a):\n",
    "    inversions = 0\n",
    "    sorted_so_far = []\n",
    "    for i, u in enumerate(a):\n",
    "        j = bisect(sorted_so_far, u)\n",
    "        inversions += i - j\n",
    "        sorted_so_far.insert(j, u)\n",
    "    return inversions\n",
    "\n",
    "\n",
    "def kendall_tau(ground_truth, predictions):\n",
    "    total_inversions = 0\n",
    "    total_2max = 0  # twice the maximum possible inversions across all instances\n",
    "    for gt, pred in zip(ground_truth, predictions):\n",
    "        ranks = [gt.index(x) for x in pred]  # rank predicted order in terms of ground truth\n",
    "        total_inversions += count_inversions(ranks)\n",
    "        n = len(gt)\n",
    "        total_2max += n * (n - 1)\n",
    "    return 1 - 4 * total_inversions / total_2max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dummy = df_valid.reset_index('cell_id').groupby('id')['cell_id'].apply(list)\n",
    "kendall_tau(y_valid, y_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall_tau(y_valid, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz('data/df_tfisd_15k.npz', df_tfisd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = sparse.load_npz('data/df_tfisd_15k.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-central-1:936697816551:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0acfb5cc8b9b47d08cdb090d2065165c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_4050a2ef43214955b71441ccb2b81e30",
        "IPY_MODEL_fca2bb6ba3f841d69f400a5988bbf197"
       ],
       "layout": "IPY_MODEL_3100ebaa768c4a2a925f01fd88a27949"
      }
     },
     "1261ea4e27024f73b4eadda2d73b8227": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_759d40e14348430eb105d803680ab918",
       "max": 156444,
       "style": "IPY_MODEL_70de017e28ef428cafc8acb176a81b22",
       "value": 156444
      }
     },
     "1796dd4f5fcb48e3b98a312bf7981fbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "198e369dc8e749cebd6d3ce82ceffb46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_7e84872f80ba48379ff99af549d1819f",
       "style": "IPY_MODEL_726c0d3439f64605bd4709fd23e871ca",
       "value": " 10797/156444 [01:49&lt;22:14, 109.12it/s]"
      }
     },
     "26be81ff7f7849f192758d17598078e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "3100ebaa768c4a2a925f01fd88a27949": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "341c849e2fea4b73a894d653886790e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4050a2ef43214955b71441ccb2b81e30": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_6dff5648cc504f76b36fc0cbb2b6962b",
       "max": 156444,
       "style": "IPY_MODEL_77b644e7736c42d69cc4145b25fe78e2",
       "value": 156444
      }
     },
     "4086800213a44bdba340a08165313cf8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "4122e0f2092f4cd78c93483a89e3bf77": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6dff5648cc504f76b36fc0cbb2b6962b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "70de017e28ef428cafc8acb176a81b22": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "726c0d3439f64605bd4709fd23e871ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "759d40e14348430eb105d803680ab918": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "77b644e7736c42d69cc4145b25fe78e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "7e84872f80ba48379ff99af549d1819f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "853261efbcfa4ee8b9988eebac247581": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "958e2b2baf4449b9ba481bf2bdb88f5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "description": "  7%",
       "layout": "IPY_MODEL_4122e0f2092f4cd78c93483a89e3bf77",
       "max": 156444,
       "style": "IPY_MODEL_fd44bc3aa17f49249cd99effb9f8f04a",
       "value": 10797
      }
     },
     "ad1e38b20a9c41bba2daac89fb518102": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_c032875e75fc4b3a8b746a3593f51e4a",
       "style": "IPY_MODEL_ba4e17e257384134b5735a305b38cc65",
       "value": " 10000/10000 [01:37&lt;00:00, 102.37it/s]"
      }
     },
     "b8b9ba1eec984cf3b30a1311c24d7fc4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1261ea4e27024f73b4eadda2d73b8227",
        "IPY_MODEL_cab3d6f80d464018a6fd1e122210d86f"
       ],
       "layout": "IPY_MODEL_853261efbcfa4ee8b9988eebac247581"
      }
     },
     "ba4e17e257384134b5735a305b38cc65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "ba8664c4b30a48a4bb1f087945e5ca09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_fd1404643ef8447ebae37eb2637fd23d",
        "IPY_MODEL_ad1e38b20a9c41bba2daac89fb518102"
       ],
       "layout": "IPY_MODEL_341c849e2fea4b73a894d653886790e6"
      }
     },
     "c032875e75fc4b3a8b746a3593f51e4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c13a237fdad84a9586aabd4a5716de2a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c33b9cf161c941778a8364030b36e29d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_958e2b2baf4449b9ba481bf2bdb88f5f",
        "IPY_MODEL_198e369dc8e749cebd6d3ce82ceffb46"
       ],
       "layout": "IPY_MODEL_1796dd4f5fcb48e3b98a312bf7981fbb"
      }
     },
     "c96c21b296154251bba1a4f2850a582a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cab3d6f80d464018a6fd1e122210d86f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_4086800213a44bdba340a08165313cf8",
       "style": "IPY_MODEL_c96c21b296154251bba1a4f2850a582a",
       "value": " 156444/156444 [00:12&lt;00:00, 12833.20it/s]"
      }
     },
     "e582b884179542e9985da5c9bfef687c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f570c2fb427f450b9d67052ea73aa97d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "fca2bb6ba3f841d69f400a5988bbf197": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e582b884179542e9985da5c9bfef687c",
       "style": "IPY_MODEL_f570c2fb427f450b9d67052ea73aa97d",
       "value": " 156444/156444 [01:12&lt;00:00, 2161.99it/s]"
      }
     },
     "fd1404643ef8447ebae37eb2637fd23d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "Train NBs: 100%",
       "layout": "IPY_MODEL_c13a237fdad84a9586aabd4a5716de2a",
       "max": 10000,
       "style": "IPY_MODEL_26be81ff7f7849f192758d17598078e3",
       "value": 10000
      }
     },
     "fd44bc3aa17f49249cd99effb9f8f04a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
