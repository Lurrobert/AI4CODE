{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c029aca-0a59-4b10-8462-a3e8a0a77925",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f26b2e8-c9ff-4e5f-a67a-5b452140a057",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"data/glove/glove.6B.100d.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        token = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[token] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9266fe63-9e8a-4b18-8945-fc24a0055ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_embeddings(embedding, cutoff=25):\n",
    "    return sorted(embeddings_dict.keys(), key=lambda token: spatial.distance.euclidean(embeddings_dict[token], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c5ca0e4-72e0-4ac6-8525-d5d211f343fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flashlight', 'twig', 'clipboard', 'shove', 'hand']\n"
     ]
    }
   ],
   "source": [
    "print(find_closest_embeddings(\n",
    "    embeddings_dict[\"twig\"] - embeddings_dict[\"branch\"] + embeddings_dict[\"hand\"]\n",
    ")[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90189727-a693-4671-a43c-c2068271a14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_a = \"Here we perform 5-fold cross validation of a KNN model after using a standard scaler\"\n",
    "sentence_b = \"In this kernel I present a very simple K-nearest neighbors model based on the quantiles of the distribution\"\n",
    "sentence_c = \"And so it begins but you can't have them all. Your heart has to settle down somewhere\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "974da328-caeb-4e3e-9612-2489fb50cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_a = np.zeros_like(embeddings_dict[\"branch\"])\n",
    "embedding_b = np.zeros_like(embeddings_dict[\"branch\"])\n",
    "embedding_c = np.zeros_like(embeddings_dict[\"branch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e41d21ad-afab-48ac-b4cb-9f8630ea50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in sentence_a.split():\n",
    "    if w not in embeddings_dict:\n",
    "        continue\n",
    "    embedding_a += embeddings_dict[w]\n",
    "\n",
    "for w in sentence_b.split():\n",
    "    if w not in embeddings_dict:\n",
    "        continue\n",
    "    embedding_b += embeddings_dict[w]\n",
    "\n",
    "for w in sentence_c.split():\n",
    "    if w not in embeddings_dict:\n",
    "        continue\n",
    "    embedding_c += embeddings_dict[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "978f38ce-15d7-46d9-8505-65288976c0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'an', 'this', 'be', 'for']\n"
     ]
    }
   ],
   "source": [
    "print(find_closest_embeddings(\n",
    "    embedding_a\n",
    ")[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "71ed5c0b-293f-4535-8e75-5545b27dc012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.454050064086914"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial.distance.euclidean(embedding_a, embedding_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de61e1ab-19ec-433d-8c12-9e71203feb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.27524185180664"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial.distance.euclidean(embedding_a, embedding_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dc70ebaf-3ab3-4c10-b4ac-967aae41047c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.673566818237305"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial.distance.euclidean(embedding_b, embedding_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa96ced0-72d5-45a4-9a69-dd7776c989b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial.distance.euclidean(embeddings_dict[token], embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ce4169-5f91-453c-bb8a-34d4c729f846",
   "metadata": {},
   "outputs": [],
   "source": [
    "return sorted(embeddings_dict.keys(), key=lambda token: spatial.distance.euclidean(embeddings_dict[token], embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfda7ec2-8148-4398-8f62-72c85479be3c",
   "metadata": {},
   "source": [
    "# bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95bf9c-1a34-4e27-bbca-a9aac98818e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20419cb0-c55e-4276-9ead-9c3fa0d4be65",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-2.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sentence-transformers) (1.11.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sentence-transformers) (0.12.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sentence-transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sentence-transformers) (0.4.0)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sentence-transformers) (4.63.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sentence-transformers) (4.17.0)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torch>=1.6.0->sentence-transformers) (4.1.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.11.6)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.49)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.3.15)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.0.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.7.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_pytorch_latest_p37/lib/python3.7/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers) (1.16.0)\n",
      "Installing collected packages: sentencepiece, nltk, sentence-transformers\n",
      "Successfully installed nltk-3.7 sentence-transformers-2.2.0 sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "! pip install -U sentence-transformers\n",
    "# https://www.sbert.net/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7421e22-3b2d-40d1-b768-852bfad2c2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a4c1e6-f320-4fc0-a6e2-66d4c3ab4faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76e0c4d-1583-48eb-a1d8-754b1be2d957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9298\n",
      "The cat sits outside \t\t The cat plays in the garden \t\t Score: 0.6497\n",
      "I love pasta \t\t Do you like pizza? \t\t Score: 0.4269\n",
      "I love pasta \t\t The new movie is so great \t\t Score: 0.2594\n",
      "I love pasta \t\t The new movie is awesome \t\t Score: 0.2528\n",
      "Do you like pizza? \t\t The new movie is awesome \t\t Score: 0.1423\n",
      "The new movie is so great \t\t Do you like pizza? \t\t Score: 0.1327\n",
      "The new movie is awesome \t\t A woman watches TV \t\t Score: 0.1318\n",
      "A woman watches TV \t\t Do you like pizza? \t\t Score: 0.1185\n",
      "The new movie is so great \t\t A woman watches TV \t\t Score: 0.0961\n"
     ]
    }
   ],
   "source": [
    "sentences = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "paraphrases = util.paraphrase_mining(model, sentences)\n",
    "\n",
    "for paraphrase in paraphrases[0:10]:\n",
    "    score, i, j = paraphrase\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb98de-5c39-45ad-ab6f-d50ee4fc4672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
