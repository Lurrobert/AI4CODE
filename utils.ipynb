{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranks(base, derived):\n",
    "    return [base.index(d) for d in derived]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_data(data_dir, NUM_TRAIN = 10000):\n",
    "    def read_notebook(path):\n",
    "        return (\n",
    "            pd.read_json(\n",
    "                path,\n",
    "                dtype={'cell_type': 'category', 'source': 'str'})\n",
    "            .assign(id=path.stem)  # final path component\n",
    "            .rename_axis('cell_id')\n",
    "        )\n",
    "\n",
    "    paths_train = list((data_dir / 'train').glob('*.json'))[:NUM_TRAIN]\n",
    "    notebooks_train = [\n",
    "      read_notebook(path) for path in tqdm(paths_train, desc='Train NBs')\n",
    "    ]\n",
    "    df = (\n",
    "      pd.concat(notebooks_train)\n",
    "      .set_index('id', append=True)\n",
    "      .swaplevel()\n",
    "      .sort_index(level='id', sort_remaining=False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def get_df_ranks(df, data_dir):\n",
    "    # train orders\n",
    "    df_orders = pd.read_csv(\n",
    "      data_dir / 'train_orders.csv',\n",
    "      index_col='id',\n",
    "      squeeze=True,\n",
    "    ).str.split()  # cell_ids str -> list\n",
    "\n",
    "\n",
    "    df_orders_ = df_orders.to_frame().join(\n",
    "      # reset only one index out of many -> \"cell_id\"; make a list out of cells in train data\n",
    "      df.reset_index('cell_id').groupby('id')['cell_id'].apply(list),\n",
    "      how='right',\n",
    "    )\n",
    "\n",
    "    ranks = {}\n",
    "    for id_, cell_order, cell_id in df_orders_.itertuples():\n",
    "        ranks[id_] = {'cell_id': cell_id, 'rank': get_ranks(cell_order, cell_id)}\n",
    "\n",
    "    df_ranks = (\n",
    "      pd.DataFrame\n",
    "      .from_dict(ranks, orient='index')\n",
    "      .rename_axis('id')\n",
    "      .apply(pd.Series.explode)\n",
    "      .set_index('cell_id', append=True)\n",
    "    )\n",
    "    # now we have\n",
    "    # id cell_id rank\n",
    "    return df_ranks\n",
    "\n",
    "def get_ancestors(data_dir, ids):\n",
    "    # Split, keeping notebooks with a common origin (ancestor_id) together\n",
    "    df_ancestors = pd.read_csv(data_dir / 'train_ancestors.csv', index_col='id')\n",
    "    return df_ancestors.loc[ids, 'ancestor_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_amazonei_pytorch_latest_p37",
   "language": "python",
   "name": "conda_amazonei_pytorch_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
